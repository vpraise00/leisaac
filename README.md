# LeIsaac ğŸš€

![leissaac](https://github.com/user-attachments/assets/45e3deda-4056-4e54-b105-d59e68222335)

This repository provides teleoperation functionality in [IsaacLab](https://isaac-sim.github.io/IsaacLab/main/index.html) using the SO101Leader ([LeRobot](https://github.com/huggingface/lerobot)), including data collection, data conversion, and subsequent policy training.

- ğŸ¤– We use SO101Follower as the robot in IsaacLab and provide relevant teleoperation method.
- ğŸ”„ We offer scripts to convert data from HDF5 format to the LeRobot Dataset.
- ğŸ§  We utilize simulation-collected data to fine-tune [GR00T N1.5](https://github.com/NVIDIA/Isaac-GR00T) and deploy it on real hardware.

***Welcome to the Lightwheel open-source community!***

Join us, contribute, and help shape the future of AI and robotics. For questions or collaboration, contact [Zeyu](mailto:zeyu.hu@lightwheel.ai) or [Yinghao](mailto:yinghao.shuai@lightwheel.ai).

## Prerequisites & Installation ğŸ› ï¸

### 1. Environment Setup

First, follow the [IsaacLab official installation guide](https://isaac-sim.github.io/IsaacLab/main/source/setup/installation/index.html) to install IsaacLab. We recommend using Conda for easier environment management. In summary, you only need to run the following command.

```bash
# Create and activate environment
conda create -n leisaac python=3.10
conda activate leisaac

# Install cuda-toolkit
conda install -c "nvidia/label/cuda-11.8.0" cuda-toolkit

# Install PyTorch
pip install torch==2.5.1 torchvision==0.20.1 --index-url https://download.pytorch.org/whl/cu118

# Install IsaacSim
pip install --upgrade pip
pip install 'isaacsim[all,extscache]==4.5.0' --extra-index-url https://pypi.nvidia.com

# Install IsaacLab
git clone git@github.com:isaac-sim/IsaacLab.git
sudo apt install cmake build-essential

cd IsaacLab
./isaaclab.sh --install
```

### 2. Clone This Repository

Clone this repository and install it as dependency.

```bash
git clone https://github.com/LightwheelAI/leisaac.git
cd leisaac
pip install -e source/leisaac
```

### 3. Install Extra Dependencies

```bash
pip install pynput pyserial deepdiff feetech-servo-sdk
```

## Asset Preparation ğŸ 

We provide an example USD assetâ€”a kitchen scene. Please download related scene [here](https://github.com/LightwheelAI/leisaac/releases/) and extract it into the `assets` directory. The directory structure should look like this:

```
<assets>
â”œâ”€â”€ robots/
â”‚   â””â”€â”€ so101_follower.usd
â””â”€â”€ scenes/
    â””â”€â”€ kitchen_with_orange/
        â”œâ”€â”€ scene.usd
        â”œâ”€â”€ assets
        â””â”€â”€ objects/
            â”œâ”€â”€ Orange001
            â”œâ”€â”€ Orange002
            â”œâ”€â”€ Orange003
            â””â”€â”€ Plate
```

We also offers more high-quality assetsâ€”visit our website ([lightwheel.ai](https://lightwheel.ai/)) for more!


## Device Setup ğŸ®

We use the SO101Leader as the teleoperation device. Please follow the [official documentation](https://huggingface.co/docs/lerobot/so101) for connection and configuration.

## Teleoperation Usage ğŸ•¹ï¸

You can run teleoperation tasks with the following script:

```shell
python scripts/environments/teleoperation/teleop_se3_agent.py \
    --task=LeIsaac-SO101-PickOrange-v0 \
    --teleop_device=so101leader \
    --num_envs=1 \
    --device=cpu \
    --enable_cameras \
    --record \
    --dataset_file=./datasets/record_data.hdf5
```

**Parameter Descriptions:**

- `--task`: Specify the task environment name to run, e.g., `LeIsaac-SO101-PickOrange-v0`.

- `--teleop_device`: Specify the teleoperation device type, e.g., `so101leader`, `keyboard`.

- `--num_envs`: Set the number of parallel simulation environments, usually `1` for teleoperation.

- `--device`: Specify the computation device, such as `cpu` or `cuda` (GPU).

- `--enable_cameras`: Enable camera sensors to collect visual data during teleoperation.

- `--record`: Enable data recording; saves teleoperation data to an HDF5 file.

- `--dataset_file`: Path to save the recorded dataset, e.g., `./datasets/record_data.hdf5`.
  
If the calibration file does not exist at the specified cache path, or if you launch with `--recalibrate`, you will be prompted to calibrate the SO101Leader.  Please refer to the [documentation](https://huggingface.co/docs/lerobot/so101#calibration-video) for calibration steps.

After entering the IsaacLab window, press the `b` key on your keyboard to start teleoperation. You can then use the specified teleop_device to control the robot in the simulation. If you need to reset the environment after completing your operation, simply press the `r` key.

**Troubleshooting:**

If you encounter permission errors like `ConnectionError`, you may need to run:

```bash
sudo chmod 666 /dev/ttyACM0
```

## Data Convention & Conversion ğŸ“Š

Collected teleoperation data is stored in HDF5 format in the specified directory. We provide a script to convert HDF5 data to the LeRobot Dataset format.  

**Note:** This script depends on the LeRobot runtime environment. We recommend using a separate Conda environment for LeRobotâ€”see the official [LeRobot repo](https://github.com/huggingface/lerobot?tab=readme-ov-file#installation) for installation instructions.

You can modify the parameters in the script and run the following command:

```bash
python scripts/convert/isaaclab2lerobot.py
```

## Policy Training ğŸ‹ï¸â€â™‚ï¸

[GR00T N1.5](https://github.com/NVIDIA/Isaac-GR00T) provides a fine-tuning workflow based on the LeRobot Dataset. You can refer to [nvidia/gr00t-n1.5-so101-tuning](https://huggingface.co/blog/nvidia/gr00t-n1-5-so101-tuning) to fine-tune it with your collected lerobot data. We take pick-orange task as an example.

- First, collect a pick-orange dataset in simulation.
- Then, fine-tune GR00T N1.5 using this data.
- Finally, deploy the trained policy on real hardware.

## Acknowledgements ğŸ™

We gratefully acknowledge [IsaacLab](https://github.com/isaac-sim/IsaacLab) and [LeRobot](https://github.com/huggingface/lerobot) for their excellent work, from which we have borrowed some code.

## Join Our Team! ğŸ’¼

We're always looking for talented individuals passionate about AI and robotics! If you're interested in:

- ğŸ¤– **Robotics Engineering**: Working with cutting-edge robotic systems and teleoperation
- ğŸ§  **AI/ML Research**: Developing next-generation AI models for robotics
- ğŸ’» **Software Engineering**: Building robust, scalable robotics software
- ğŸ”¬ **Research & Development**: Pushing the boundaries of what's possible in robotics

**Join us at Lightwheel AI!** We offer:
- Competitive compensation and benefits
- Work with state-of-the-art robotics technology
- Collaborative, innovative environment
- Opportunity to shape the future of AI-powered robotics

**[Apply Now â†’](https://lightwheel.ai/career)** | **[Contact Now â†’](mailto:zeyu.hu@lightwheel.ai)** | **[Learn More About Us â†’](https://lightwheel.ai)**

---

**Let's build the future of robotics together! ğŸ¤**

---
